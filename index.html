<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>JuliÃ¡n  Tachella</title>
    <meta name="author" content="JuliÃ¡n  Tachella" />
    <meta name="description" content="signal processing >" />
    <meta name="keywords" content="signal processing, computational imaging, CNRS, deep learning" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ“¡</text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://tachella.github.io/"><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GG3QB6QQXF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GG3QB6QQXF');
</script>

  
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://tachella.github.io/"><span class="font-weight-bold">JuliÃ¡n</span>   Tachella</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/Join%20Us/">Join Us</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/people/">People</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Research</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/talks/">Talks</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">JuliÃ¡n</span>  Tachella
          </h1>
          <p class="desc"><a href="https://www.cnrs.fr/" target="_blank" rel="noopener noreferrer">CNRS</a> &amp; <a href="http://www.ens-lyon.fr/" target="_blank" rel="noopener noreferrer">ENS de Lyon</a></p>
        </header>

        <article>
          <div class="profile float-right">
<figure>
  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/profile2-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/profile2-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/profile2-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="/assets/img/profile2.jpg" alt="profile2.jpg">
  </picture>
</figure>

            <div class="address">
              <p> julian.tachella@cnrs.fr</p>
            </div>
          </div>

          <div class="clearfix">
            <p>I am a research scientist at the French National Centre for Scientific Research <a href="https://www.cnrs.fr/" target="_blank" rel="noopener noreferrer">CNRS</a>, working at the <a href="http://www.ens-lyon.fr/PHYSIQUE/teams/signaux-systemes-physique" target="_blank" rel="noopener noreferrer">Sisyph laboratory</a>, <a href="http://www.ens-lyon.fr/" target="_blank" rel="noopener noreferrer">Ã‰cole Normale SupÃ©rieure de Lyon</a> (Lyon, France). My research lies at the intersection of signal processing and machine learning. I am particularly interested in the theory of imaging inverse problems and applications in computational imaging.</p>

<p>I am a lead developer of the <a href="https://deepinv.github.io/deepinv/" target="_blank" rel="noopener noreferrer">deep inverse</a>, a library for solving inverse problems with deep learning.</p>

<p><strong>Open PhD and master positions</strong> can be found <a href="/Join%20Us/">here</a>.</p>

<p><strong>Code</strong> and videos related to my publications can be found <a href="/publications/">here</a>.</p>

          </div>

          <!-- News -->          
          <div class="news">
            <h2>news</h2>
            <div class="table-responsive">
              <table class="table table-sm table-borderless"> 
                <tr>
                  <th scope="row">Jan 21, 2024</th>
                  <td>
                    <a href="https://arxiv.org/abs/2310.11838" target="_blank" rel="noopener noreferrer">The equivariant bootstrap</a> is accepted at AISTATSâ€™24 with oral presentation.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Oct 23, 2023</th>
                  <td>
                    <a href="https://arxiv.org/abs/2303.08691" target="_blank" rel="noopener noreferrer">Our paper on binary learning</a> has been accepted in TMLR with a Featured certification!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Oct 20, 2023</th>
                  <td>
                    We have two open master positions for next year. Find more details <a href="https://tachella.github.io/openings/">here</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Sep 26, 2023</th>
                  <td>
                    Open postdoc position in multilevel unfolded networks for imaging inverse problems. Find more details <a href="/assets/pdf/postdoc_offer_unfolded_multilevel.pdf">here</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jul 6, 2023</th>
                  <td>
                    The UNLIP project <a href="https://anr.fr/fr/detail/call/aapg-appel-a-projets-generique-2023/" target="_blank" rel="noopener noreferrer">will be funded by the ANR</a>.
Job openings are coming soon!
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

          <!-- Selected papers -->
          <div class="publications">
            <h2>selected publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 container_img"><div class="card hooverable">
            <img class="card-img-top" src="https://tachella.github.io/assets/img/tachella2023equivariant.png">
          </div></div>

        <!-- Entry bib key -->
        <div id="tachella2023equivariant" class="col-sm-8">
        
          <!-- Title -->  
          <div class="title">Equivariant Bootstrapping for Uncertainty Quantification in Imaging Inverse Problems</div>
          <!-- Author -->
          <div class="author">
                  <em>Tachella, Julian</em>,Â and Pereyra, Marcelo
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>AISTATS 2024, Oral Presentation</em> 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2310.11838" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a href="https://github.com/tachella/equivariant_bootstrap" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Scientific imaging problems are often severely ill-posed, and hence have significant intrinsic uncertainty. Accurately quantifying the uncertainty in the solutions to such problems is therefore critical for the rigorous interpretation of experimental results as well as for reliably using the reconstructed images as scientific evidence. Unfortunately, existing imaging methods are unable to quantify the uncertainty in the reconstructed images in a manner that is robust to experiment replications. This paper presents a new uncertainty quantification methodology based on an equivariant formulation of the parametric bootstrap algorithm that leverages symmetries and invariance properties commonly encountered in imaging problems. Additionally, the proposed methodology is general and can be easily applied with any image reconstruction technique, including unsupervised training strategies that can be trained from observed data alone, thus enabling uncertainty quantification in situations where there is no ground truth data available. We demonstrate the proposed approach with a series of numerical experiments and through comparisons with alternative uncertainty quantification strategies from the state-of-the-art, such as Bayesian strategies involving score-based diffusion models and Langevin samplers. In all our experiments, the proposed method delivers remarkably accurate high-dimensional confidence regions and outperforms the competing approaches in terms of estimation accuracy, uncertainty quantification accuracy, and computing time.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 container_img"><div class="card hooverable">
            <img class="card-img-top" src="https://tachella.github.io/assets/img/imagingequiv.png">
          </div></div>

        <!-- Entry bib key -->
        <div id="tachella2023spm" class="col-sm-8">
        
          <!-- Title -->  
          <div class="title">Imaging with Equivariant Deep Learning</div>
          <!-- Author -->
          <div class="author">Chen, Dongdong,Â Davies, Mike,Â Ehrhardt, Matthias J,Â SchÃ¶nlieb, Carola-Bibiane,Â Sherry, Ferdia,Â and <em>Tachella, Julian</em>
                
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Signal Processing Magazine</em> 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2209.01725" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a href="https://ieeexplore.ieee.org/abstract/document/10004796" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="/projects/equivariantimaging" class="btn btn-sm z-depth-0" role="button">Project</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>From early image processing to modern computational imaging, successful models and algorithms have relied on a fundamental property of natural signals: symmetry . Here symmetry refers to the invariance property of signal sets to transformations, such as translation, rotation, or scaling. Symmetry can also be incorporated into deep neural networks (DNNs) in the form of equivariance, allowing for more data-efficient learning. While there have been important advances in the design of end-to-end equivariant networks for image classification in recent years, computational imaging introduces unique challenges for equivariant network solutions since we typically only observe the image through some noisy ill-conditioned forward operator that itself may not be equivariant. We review the emerging field of equivariant imaging (EI) and show how it can provide improved generalization and new imaging opportunities. Along the way, we show the interplay between the acquisition physics and group actions and links to iterative reconstruction, blind compressed sensing, and self-supervised learning.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 container_img"><div class="card hooverable">
            <img class="card-img-top" src="https://tachella.github.io/assets/img/m_regimes_website.png">
          </div></div>

        <!-- Entry bib key -->
        <div id="tachella2022sampling" class="col-sm-8">
        
          <!-- Title -->  
          <div class="title">Sensing Theorems for Unsupervised Learning in Linear Inverse Problems</div>
          <!-- Author -->
          <div class="author">
                  <em>Tachella, Julian</em>,Â Chen, Dongdong,Â and Davies, Mike
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of Machine Learning Research (JMLR)</em> Jan 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2203.12513" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a href="http://jmlr.org/papers/v24/22-0315.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="/projects/equivariantimaging" class="btn btn-sm z-depth-0" role="button">Project</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Solving a linear inverse problem requires knowledge about the underlying signal model. In many applications, this model is a priori unknown and has to be learned from data. However, it is impossible to learn the model using observations obtained via a single incomplete measurement operator, as there is no information outside the range of the inverse operator, resulting in a chicken-and-egg problem: to learn the model we need reconstructed signals, but to reconstruct the signals we need to know the model. Two ways to overcome this limitation are using multiple measurement operators or assuming that the signal model is invariant to a certain group action. In this paper, we present necessary and sufficient sensing conditions for learning the signal model from partial measurements which only depend on the dimension of the model, and the number of operators or properties of the group action that the model is invariant to. As our results are agnostic of the learning algorithm, they shed light into the fundamental limitations of learning from incomplete data and have implications in a wide range set of practical algorithms, such as dictionary learning, matrix completion and deep neural networks.</p>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%6A%75%6C%69%61%6E.%74%61%63%68%65%6C%6C%61@%65%6E%73-%6C%79%6F%6E.%66%72" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=u_hH-fUAAAAJ&amp;hl" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/tachella" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://twitter.com/TachellaJulian" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            <a href="https://gitlab.com/Tachella" title="GitLab" target="_blank" rel="noopener noreferrer"><i class="fab fa-gitlab"></i></a>
            
            </div>

            <div class="contact-note">
              The best way to reach me is by email.

            </div>
            
          </div>
        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2024 JuliÃ¡n  Tachella. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  
    <!-- Mathjax Support -->
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

    
  </body>
</html>

