---
---

@string{aps = {American Physical Society,}}

@article{tachella2022sampling,
  title={Sampling Theorems for Learning from Incomplete Measurements},
  author={Tachella, Julian and Chen, Dongdong and Davies, Mike},
  journal={arXiv preprint},
  arxiv={2201.12151},
  year={2022},
  month = {January},
  abstract = {In many real-world settings, only incomplete measurement data are available which can pose a problem for learning. Unsupervised learning of the signal model using a fixed incomplete measurement process is impossible in general, as there is no information in the nullspace of the measurement operator. This limitation can be overcome by using measurements from multiple operators. While this idea has been successfully applied in various applications, a precise characterization of the conditions for learning is still lacking. In this paper, we fill this gap by presenting necessary and sufficient conditions for learning the signal model which indicate the interplay between the number of distinct measurement operators G, the number of measurements per operator m, the dimension of the model k and the dimension of the signals n. In particular, we show that generically unsupervised learning is possible if each operator obtains at least m>k+n/G measurements. Our results are agnostic of the learning algorithm and have implications in a wide range of practical algorithms, from low-rank matrix recovery to deep neural networks.},
}

@article{chen2021robust,
  title={Robust Equivariant Imaging: a fully unsupervised framework for learning to image from noisy and partial measurements},
  author={Chen, Dongdong and Tachella, Julian and Davies, Mike E},
  journal={arXiv preprint arXiv:2111.12855},
  year={2021},
  blog = {2021-10-01-equivariant},
  arxiv={2111.12855},
  month = {December},
  abstract = {Deep networks provide state-of-the-art performance in multiple imaging inverse problems ranging from medical imaging to computational photography. However, most existing networks are trained with clean signals which are often hard or impossible to obtain. Equivariant imaging (EI) is a recent self-supervised learning framework that exploits the group invariance present in signal distributions to learn a reconstruction function from partial measurement data alone. While EI results are impressive, its performance degrades with increasing noise. In this paper, we propose a Robust Equivariant Imaging (REI) framework which can learn to image from noisy partial measurements alone. The proposed method uses Stein's Unbiased Risk Estimator (SURE) to obtain a fully unsupervised training loss that is robust to noise. We show that REI leads to considerable performance gains on linear and nonlinear inverse problems, thereby paving the way for robust unsupervised imaging with deep networks.},
}

@inproceedings{chen2021equivariant,
  title={Equivariant Imaging: Learning Beyond the Range Space},
  author={Chen, Dongdong and Tachella, Julian and Davies, Mike E},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4379--4388},
  year={2021},
  blog = {2021-10-01-equivariant},
  pdf ={https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Equivariant_Imaging_Learning_Beyond_the_Range_Space_ICCV_2021_paper.pdf},
  sup ={https://openaccess.thecvf.com/content/ICCV2021/supplemental/Chen_Equivariant_Imaging_Learning_ICCV_2021_supplemental.zip}, 
  month = {March},
  abbr = {chen2021equivariant.jpg},
  code = {https://github.com/edongdongchen/EI},
  selected={true},
abstract = {In various imaging problems, we only have access to compressed measurements of the underlying signals, hindering most learning-based strategies which usually require pairs of signals and associated measurements for training. Learning only from compressed measurements is impossible in general, as the compressed observations do not contain information outside the range of the forward sensing operator. We propose a new end-to-end self-supervised framework that overcomes this limitation by exploiting the equivariances present in natural signals. Our proposed learning strategy performs as well as fully supervised methods. Experiments demonstrate the potential of this framework on inverse problems including sparse-view X-ray computed tomography on real clinical data and image inpainting on natural images.},
}

@article{sheehan2021sketching,
  title={A sketching framework for reduced data transfer in photon counting lidar},
  author={Sheehan, Michael P and Tachella, Julian and Davies, Mike E},
  journal={IEEE Transactions on Computational Imaging},
  volume={7},
  pages={989--1004},
  year={2021},
  arxiv = {2102.08732},
  abbr = {sheehan2021sketching.gif},
  pdf = {https://ieeexplore.ieee.org/abstract/document/9541047},
  code = {https://gitlab.com/Tachella/sketched_lidar},
  abstract = {Single-photon lidar has become a prominent tool for depth imaging in recent years. At the core of the technique, the depth of a target is measured by constructing a histogram of time delays between emitted light pulses and detected photon arrivals. A major data processing bottleneck arises on the device when either the number of photons per pixel is large or the resolution of the time-stamp is fine, as both the space requirement and the complexity of the image reconstruction algorithms scale with these parameters. We solve this limiting bottleneck of existing lidar techniques by sampling the characteristic function of the time of flight (ToF) model to build a compressive statistic, a so-called sketch of the time delay distribution, which is sufficient to infer the spatial distance and intensity of the object. The size of the sketch scales with the degrees of freedom of the ToF model (number of objects) and not, fundamentally, with the number of photons or the time-stamp resolution. Moreover, the sketch is highly amenable for on-chip online processing. We show theoretically that the loss of information for compression is controlled and the mean squared error of the inference quickly converges towards the optimal Cram√©r-Rao bound (i.e. no loss of information) for modest sketch sizes. The proposed compressed single-photon lidar framework is tested and evaluated on real life datasets of complex scenes where it is shown that a compression rate of up-to 150 is achievable in practice without sacrificing the overall resolution of the reconstructed image.},
}

@inproceedings{tachella2021nonlocal,
    author    = {Tachella, Julian and Tang, Junqi and Davies, Mike},
    title     = {The Neural Tangent Link Between CNN Denoisers and Non-Local Filters},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {8618-8627},
	abbr = {tachella2021nonlocal.png},
	code = {https://gitlab.com/Tachella/neural_tangent_denoiser},
    pdf = {https://openaccess.thecvf.com/content/CVPR2021/papers/Tachella_The_Neural_Tangent_Link_Between_CNN_Denoisers_and_Non-Local_Filters_CVPR_2021_paper.pdf},
    sup = {https://openaccess.thecvf.com/content/CVPR2021/supplemental/Tachella_The_Neural_Tangent_CVPR_2021_supplemental.pdf},
 selected={true},
 youtube = {vLxzxp2boyY},
 abstract = {Convolutional Neural Networks (CNNs) are now a well-established tool for solving computational imaging problems. Modern CNN-based algorithms obtain state-of-the-art performance in diverse image restoration problems. Furthermore, it has been recently shown that, despite being highly overparameterized, networks trained with a single corrupted image can still perform as well as fully trained networks. We introduce a formal link between such networks through their neural tangent kernel (NTK), and well-known non-local filtering techniques, such as non-local means or BM3D. The filtering function associated with a given network architecture can be obtained in closed form without need to train the network, being fully characterized by the random initialization of the network weights. While the NTK theory accurately predicts the filter associated with networks trained using standard gradient descent, our analysis shows that it falls short to explain the behaviour of networks trained using the popular Adam optimizer. The latter achieves a larger change of weights in hidden layers, adapting the non-local filtering function during training. We evaluate our findings via extensive image denoising experiments.},
}


@article{rapp2020seeing,
  title={Seeing around corners with edge-resolved transient imaging},
  author={Rapp, Joshua and Saunders, Charles and Tachella, Julian and Murray-Bruce, John and Altmann, Yoann and Tourneret, Jean-Yves and McLaughlin, Stephen and Dawson, Robin and Wong, Franco NC and Goyal, Vivek K},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--10},
  year={2020},
  publisher={Nature Publishing Group},
  abbr = {rapp2020seeing.gif},
  code = {https://github.com/tachella/ERTI},
  pdf = {https://www.nature.com/articles/s41467-020-19727-4.pdf},
  youtube = {1MDwFVky-wg},
}


@inproceedings{tachella2019crt3d,
	author={{Tachella}, Julian and {Altmann}, Yoann and {McLaughlin}, Stephen and {Tourneret}, Jean-Yves},
	booktitle={Proc. 8th Int. Workshop Comput. Adv. Multi-Sensor Adap. Process. (CAMSAP)}, 
	title={Real-time 3{D} color imaging with single-photon lidar data}, 
	year={2019}, 
	volume={}, 
	number={}, 
	address = {Guadaloupe, West Indies},
	pages={1-5}, 
	doi={10.1109/CAMSAP.2017.8313128}, 
	abbr = {tachella2019crt3d.gif},
	code = {https://gitlab.com/Tachella/real-time-single-photon-lidar},
	month={Dec},}

@article{rapp2020advances,
  title={Advances in single-photon lidar for autonomous vehicles: Working principles, challenges, and recent advances},
  author={Rapp, Joshua and Tachella, Julian and Altmann, Yoann and McLaughlin, Stephen and Goyal, Vivek K},
  journal={IEEE Signal Processing Magazine},
  volume={37},
  number={4},
  pages={62--71},
  year={2020},
  month = {June},
  abbr = {rapp2020advances.png},
  pdf = {https://ieeexplore.ieee.org/document/9127841},
  publisher={IEEE},
}

@article{tachella2019musapop,
	author = {{Tachella}, Julian and {Altmann}, Yoann and {M{\'a}rquez}, Miguel and
	{Arguello-Fuentes}, Henry and {Tourneret}, Jean-Yves and
	{McLaughlin}, Stephen},
	title = {Bayesian 3{D} Reconstruction of Subsampled Multispectral Single-photon Lidar Signals},
	journal = {IEEE Trans. Comput. Imag.},
	keywords = {Electrical Engineering and Systems Science - Signal Processing},
	year = {2019},
	abbr = {tachella2019musapop.gif},
	code = {https://gitlab.com/Tachella/musapop},
	pdf = {https://ieeexplore.ieee.org/document/8854866},
	abstract = {Light detection and ranging (Lidar) single-photon devices capture range and intensity information from a three-dimensional (3-D) scene. This modality enables long range 3-D reconstruction with high range precision and low laser power. A multispectral single-photon Lidar system provides additional spectral diversity, allowing the discrimination of different materials. However, the main drawback of such systems can be the long acquisition time needed to collect enough photons in each spectral band. In this work, we tackle this problem in two ways: first, we propose a Bayesian 3-D reconstruction algorithm that is able to find multiple surfaces per pixel, using few photons, i.e., shorter acquisitions. In contrast to previous algorithms, the novel method processes jointly all the spectral bands, obtaining better reconstructions using less photon detections. The proposed model promotes spatial correlation between neighbouring points within a given surface using spatial point processes. Secondly, we account for different spatial and spectral subsampling schemes, which reduce the total number of measurements, without significant degradation of the reconstruction performance. In this way, the total acquisition time, memory requirements and computational time can be significantly reduced. The experiments performed using both synthetic and real single-photon Lidar data demonstrate the advantages of tailored sampling schemes over random alternatives. Furthermore, the proposed algorithm yields better estimates than other existing methods for multi-surface reconstruction using multispectral Lidar data.},
	month = {Apr},
}

@article{tachella2019manipop,
	author = {Tachella, J. and Altmann, Y. and Ren, X. and McCarthy, A. and Buller, G. and McLaughlin, S. and Tourneret, J.},
	title = {Bayesian 3{D} Reconstruction of Complex Scenes from Single-Photon Lidar Data},
	journal = {SIAM Journal on Imaging Sciences},
	volume = {12},
	number = {1},
	pages = {521-550},
	year = {2019},
	abbr = {tachella2019manipop.gif},
	doi = {10.1137/18M1183972},
	arxiv = {1810.11633},
	abstract = {Light detection and ranging (Lidar) data can be used to capture the depth and intensity profile of a 3D scene. This modality relies on constructing, for each pixel, a histogram of time delays between emitted light pulses and detected photon arrivals. In a general setting, more than one surface can be observed in a single pixel. The problem of estimating the number of surfaces, their reflectivity and position becomes very challenging in the low-photon regime (which equates to short acquisition times) or relatively high background levels (i.e., strong ambient illumination). This paper presents a new approach to 3D reconstruction using single-photon, single-wavelength Lidar data, which is capable of identifying multiple surfaces in each pixel. Adopting a Bayesian approach, the 3D structure to be recovered is modelled as a marked point process and reversible jump Markov chain Monte Carlo (RJ-MCMC) moves are proposed to sample the posterior distribution of interest. In order to promote spatial correlation between points belonging to the same surface, we propose a prior that combines an area interaction process and a Strauss process. New RJ-MCMC dilation and erosion updates are presented to achieve an efficient exploration of the configuration space. To further reduce the computational load, we adopt a multiresolution approach, processing the data from a coarse to the finest scale. The experiments performed with synthetic and real data show that the algorithm obtains better reconstructions than other recently published optimization algorithms for lower execution times.},
	pdf = {https://hal.archives-ouvertes.fr/hal-02185077/document},
	code = {https://gitlab.com/Tachella/manipop},
	youtube = {pk0tLCCqnVk},
}


@article{tachella2019rt3d,
	author = {Tachella, J. and Altmann, Y. and Mellado, N. and Tobin, R.and  McCarthy, A. and Buller, G. and Tourneret, J. and McLaughlin, S.},
	title = {{Real-time 3D reconstruction from single-photon lidar data using plug-and-play point cloud denoisers}},
	journal = {Nature Communications},
	number = {10},
	pages = {4984},
	year = {2019},
	doi = {10.1137/18M1183972},
	abbr = {tachella2019rt3d.gif},
	code = {https://gitlab.com/Tachella/real-time-single-photon-lidar},
	pdf = {https://www.nature.com/articles/s41467-019-12943-7.pdf},
 	selected={true},
}


@inproceedings{tachellagenmanipop,
	author={{Tachella}, Julian and {Altmann}, Yoann and {McLaughlin}, Stephen and {Tourneret}, Jean-Yves},
	booktitle={Proc. Int. Conf. on Acoustics, Speech and Signal Process. (ICASSP)},
	title={3D Reconstruction Using Single-photon Lidar Data Exploiting the Widths of the Returns},
	year={2019},
	volume={},
	number={},
	pages={7815-7819},
	ISSN={1520-6149},
	code = {https://gitlab.com/Tachella/generalized-manipop},
	month={May},
	abbr = {tachellagenmanipop.gif},
}

@inproceedings{tachella2019detection1,
	author={{Tachella}, Julian and {Altmann}, Yoann and {McLaughlin}, Stephen and {Tourneret}, Jean-Yves},
	booktitle={Proc. 27th Eur. Signal Process. Conf. (EUSIPCO)},
	title={Fast Surface Detection in Single-Photon Lidar Waveforms},
	year={2019},
	volume={},
	number={},
	pages={1-5},
	ISSN={2219-5491},
	abbr = {tachella2019detection.png},
	address = {A Coruna, Spain},
	code = {https://gitlab.com/Tachella/lidardetection},
	pdf = {https://ieeexplore.ieee.org/document/8903062},
	abs = {Single-photon light detection and ranging (Lidar) devices can be used to obtain range and reflectivity information from 3D scenes. However, reconstructing the 3D surfaces from the raw waveforms can be very challenging, in particular when the number of spurious background detections is large compared to the number of signal detections. This paper introduces a new and fast detection algorithm, which can be used to assess the presence of objects/surfaces in each waveform, allowing only the histograms where the imaged surfaces are present to be further processed. The method is compared to state-of-the-art 3D reconstruction methods using synthetic and real single-photon data and the results illustrate its benefits for fast and robust target detection using single-photon data.},
	month={Sep.},}

@inproceedings{tachelladetection2,
	author={{Tachella}, Julian and {Altmann}, Yoann and {McLaughlin}, Stephen and {Tourneret}, Jean-Yves},
	title = {{On fast object detection using single-photon lidar data}},
	volume = {11138},
	booktitle = {Proc. SPIE Wavelets and Sparsity XVIII},
	publisher = {SPIE},
	address = {San Diego, USA},
	pages = {252 -- 261},
	year = {2019},
	month = {Sep},
	pdf = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11138/111380T/On-fast-object-detection-using-single-photon-lidar-data/10.1117/12.2527685.short},
	abstract = {Light detection and ranging (Lidar) systems based on single-photon detection can be used to obtain range and reflectivity information from 3D scenes with high range resolution. However, reconstructing the 3D surfaces from the raw single-photon waveforms is challenging, in particular when a limited number of photons is detected and when the ratio of spurious background detection events is large. This paper reviews a set of fast detection algorithms, which can be used to assess the presence of objects/surfaces in each waveform, allowing only the histograms where the imaged surfaces are present to be further processed. The original method we recently proposed is extended here using a multiscale approach to further reduce the computational complexity of the detection process. The proposed methods are compared to state-of-the-art 3D reconstruction methods using synthetic and real single-photon data and the results illustrate their benefits for fast and robust target detection.},
	code = {https://gitlab.com/Tachella/lidardetection},
	doi = {10.1117/12.2527685},
}


@inproceedings{tachella2018mcmc,
	author={{Tachella}, Julian and {Altmann}, Pereyra, Marcelo and Yoann and {McLaughlin}, Stephen and {Tourneret}, Jean-Yves},
	booktitle={Proc. 26th Eur. Signal Process. Conf. (EUSIPCO)},
	title={Bayesian Restoration of High-Dimensional Photon-Starved Images},
	year={2018},
	volume={},
	number={},
	pages={747-751},
	doi={10.23919/EUSIPCO.2018.8553175},
	ISSN={2219-5491},
	address = {Rome, Italy},
	pdf = {https://ieeexplore.ieee.org/abstract/document/8553175},
	abbr = {tachella2018mcmc.png},
	abstract = {This paper investigates different algorithms to perform image restoration from single-photon measurements corrupted with Poisson noise. The restoration problem is formulated in a Bayesian framework and several state-of-the-art Monte Carlo samplers are considered to estimate the unknown image and quantify its uncertainty. The different samplers are compared through a series of experiments conducted with synthetic images. The results demonstrate the scaling properties of the proposed samplers as the dimensionality of the problem increases and the number of photons decreases. Moreover, our experiments show that for a certain photon budget (i.e., acquisition time of the imaging device), downsampling the observations can yield better reconstruction results.},
	month={Sep.},}
