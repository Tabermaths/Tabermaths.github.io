<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 3D Reconstruction From Single-Photon Data | Julian Tachella </title> <meta name="author" content="Julian Tachella"> <meta name="description" content="Machine learning research scientist at CNRS. "> <meta name="keywords" content="machine learning, signal processing, computational imaging, CNRS, deep learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%A1&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tachella.github.io/projects/3Dreconstruction/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Julian</span> Tachella </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/Join%20Us/">Join Us </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">Talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">3D Reconstruction From Single-Photon Data</h1> <p class="post-description"></p> </header> <article> <p>Single-photon light detection and ranging (lidar) has emerged as a prime candidate technology for depth imaging through challenging environments. This modality relies on constructing, for each pixel, a histogram of time delays between emitted light pulses and detected photon arrivals. The problem of estimating the number of imaged surfaces, their reflectivity and position becomes very challenging in the low-photon regime (which equates to short acquisition times) or relatively high background levels (i.e., strong ambient illumination).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/lidar_summary-480.webp 480w,/assets/img/lidar_summary-800.webp 800w,/assets/img/lidar_summary-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/lidar_summary.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Schematic of 3D reconstruction from lidar data" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>In a general setting, a variable number of surfaces can be observed per imaged pixel. The majority of existing methods assume exactly one surface per pixel, simplifying the reconstruction problem so that standard image processing techniques can be easily applied. However, this assumption hinders practical three-dimensional (3D) imaging applications, being restricted to controlled indoor scenarios. Moreover, other existing methods that relax this assumption achieve worse reconstructions, suffering from long execution times and large memory requirements.</p> <p>This project focuses on novel approaches to 3D reconstruction from single-photon lidar data, which are capable of identifying multiple surfaces in each pixel. A first approach to multi-depth consists of detecting in which pixels a target is present. Limiting the number of surfaces per pixel to 0 or 1 can significantly reduce the complexity of the reconstructions algorithms, while still tackling a wide range of practical imaging scenarios. Detection methods can be found in <a class="citation" href="#tachella2019detection1">(Tachella et al., 2019)</a> and <a class="citation" href="#tachella2019detection2">(Tachella et al., 2019)</a>.</p> <p>The models proposed in <a class="citation" href="#tachella2019manipop">(Tachella et al., 2019)</a>, <a class="citation" href="#tachella2019genmanipop">(Tachella et al., 2019)</a>, <a class="citation" href="#tachella2019rt3d">(Tachella et al., 2019)</a> and <a class="citation" href="#tachella2019crt3d">(Tachella et al., 2019)</a> differ from standard image processing tools, being designed to capture correlations of manifold-like structures.</p> <p>Until now, a major limitation has been the significant amount of time required for the analysis of the recorded data. By combining statistical models with highly scalable computational tools from the computer graphics community, we demonstrate 3D reconstruction of complex outdoor scenes with processing times of the order of 20 ms, where the lidar data was acquired in broad daylight from distances up to 320 m <a class="citation" href="#tachella2019rt3d">(Tachella et al., 2019)</a>. This has enabled robust, real-time target reconstruction of complex moving scenes, paving the way for single-photon lidar at video rates for practical 3D imaging applications</p> <p>Multispectral lidar (MSL) systems gather measurements at many spectral bands, making it possible to distinguish distinct materials. The MSL modality consists of constructing one histogram of time delays per wavelength. 3D reconstruction from MSL data imposes an additional challenge as the data to be processed can become prohibitive. A way to overcome this limitation is through the use of compressive strategies on the spatial domain <a class="citation" href="#tachella2019manipop">(Tachella et al., 2019)</a>.</p> <p>A comprehensive survey of 3D reconstruction methods can be found in <a class="citation" href="#rapp2020advances">(Rapp et al., 2020)</a>.</p> <h3 id="related-papers">Related papers</h3> <div class="publications"> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/rapp2020advances-480.webp 480w,/assets/img/publication_preview/rapp2020advances-800.webp 800w,/assets/img/publication_preview/rapp2020advances-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/rapp2020advances.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rapp2020advances.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="rapp2020advances" class="col-sm-8"> <div class="title">Advances in single-photon lidar for autonomous vehicles: Working principles, challenges, and recent advances</div> <div class="author"> Joshua Rapp , <em>Julian Tachella</em>, Yoann Altmann , Stephen McLaughlin , and Vivek K Goyal </div> <div class="periodical"> <em>IEEE Signal Processing Magazine</em>, Jun 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/9127841" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>The safety and success of autonomous vehicles (AVs) depend on their ability to accurately map and respond to their surroundings in real time. One of the most promising recent technologies for depth mapping is single-photon lidar (SPL), which measures the time of flight of individual photons. The long-range capabilities (kilometers), excellent depth resolution (centimeters), and use of low-power (eye-safe) laser sources renders this modality a strong candidate for use in AVs. While presenting unique opportunities, the remarkable sensitivity of single-photon detectors introduces several signal processing challenges. The discrete nature of photon counting and the particular design of the detection devices means the acquired signals cannot be treated as arising in a linear system with additive Gaussian noise. Moreover, the number of useful photon detections may be small despite a large data volume, thus requiring careful modeling and algorithmic design for real-time performance. This article discusses the main working principles of SPL and summarizes recent advances in signal processing techniques for this modality, highlighting promising applications in AVs as well as a number of challenges for vehicular lidar that cannot be solved by better hardware alone.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tachella2019detection-480.webp 480w,/assets/img/publication_preview/tachella2019detection-800.webp 800w,/assets/img/publication_preview/tachella2019detection-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tachella2019detection.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tachella2019detection.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tachella2019detection1" class="col-sm-8"> <div class="title">Fast Surface Detection in Single-Photon Lidar Waveforms</div> <div class="author"> <em>Julian Tachella</em>, Yoann Altmann , Stephen McLaughlin , and Jean-Yves Tourneret </div> <div class="periodical"> <em>In Proc. 27th Eur. Signal Process. Conf. (EUSIPCO)</em> , Sep 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/8903062" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/Tachella/lidardetection" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="tachella2019detection2" class="col-sm-8"> <div class="title">On fast object detection using single-photon lidar data</div> <div class="author"> <em>Julian Tachella</em>, Yoann Altmann , Stephen McLaughlin , and Jean-Yves Tourneret </div> <div class="periodical"> <em>In Proc. SPIE Wavelets and Sparsity XVIII</em> , Sep 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11138/111380T/On-fast-object-detection-using-single-photon-lidar-data/10.1117/12.2527685.short" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitlab.com/Tachella/lidardetection" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Light detection and ranging (Lidar) systems based on single-photon detection can be used to obtain range and reflectivity information from 3D scenes with high range resolution. However, reconstructing the 3D surfaces from the raw single-photon waveforms is challenging, in particular when a limited number of photons is detected and when the ratio of spurious background detection events is large. This paper reviews a set of fast detection algorithms, which can be used to assess the presence of objects/surfaces in each waveform, allowing only the histograms where the imaged surfaces are present to be further processed. The original method we recently proposed is extended here using a multiscale approach to further reduce the computational complexity of the detection process. The proposed methods are compared to state-of-the-art 3D reconstruction methods using synthetic and real single-photon data and the results illustrate their benefits for fast and robust target detection.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tachella2019manipop-480.webp 480w,/assets/img/publication_preview/tachella2019manipop-800.webp 800w,/assets/img/publication_preview/tachella2019manipop-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tachella2019manipop.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tachella2019manipop.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tachella2019manipop" class="col-sm-8"> <div class="title">Bayesian 3D Reconstruction of Complex Scenes from Single-Photon Lidar Data</div> <div class="author"> <em>Julian Tachella</em>, Yoann Altmann , Ximing Ren , Angus McCarthy , Gerald Buller , Steve McLaughlin , and Jean-Yves Tourneret </div> <div class="periodical"> <em>SIAM Journal on Imaging Sciences</em>, Sep 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/1810.11633" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://hal.archives-ouvertes.fr/hal-02185077/document" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://gitlab.com/Tachella/manipop" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Light detection and ranging (Lidar) data can be used to capture the depth and intensity profile of a 3D scene. This modality relies on constructing, for each pixel, a histogram of time delays between emitted light pulses and detected photon arrivals. In a general setting, more than one surface can be observed in a single pixel. The problem of estimating the number of surfaces, their reflectivity and position becomes very challenging in the low-photon regime (which equates to short acquisition times) or relatively high background levels (i.e., strong ambient illumination). This paper presents a new approach to 3D reconstruction using single-photon, single-wavelength Lidar data, which is capable of identifying multiple surfaces in each pixel. Adopting a Bayesian approach, the 3D structure to be recovered is modelled as a marked point process and reversible jump Markov chain Monte Carlo (RJ-MCMC) moves are proposed to sample the posterior distribution of interest. In order to promote spatial correlation between points belonging to the same surface, we propose a prior that combines an area interaction process and a Strauss process. New RJ-MCMC dilation and erosion updates are presented to achieve an efficient exploration of the configuration space. To further reduce the computational load, we adopt a multiresolution approach, processing the data from a coarse to the finest scale. The experiments performed with synthetic and real data show that the algorithm obtains better reconstructions than other recently published optimization algorithms for lower execution times.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <iframe src="https://youtu.be/pk0tLCCqnVk" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tachellagenmanipop-480.webp 480w,/assets/img/publication_preview/tachellagenmanipop-800.webp 800w,/assets/img/publication_preview/tachellagenmanipop-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tachellagenmanipop.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tachellagenmanipop.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tachella2019genmanipop" class="col-sm-8"> <div class="title">3D Reconstruction Using Single-photon Lidar Data Exploiting the Widths of the Returns</div> <div class="author"> <em>Julian Tachella</em>, Yoann Altmann , Stephen McLaughlin , and Jean-Yves Tourneret </div> <div class="periodical"> <em>In Proc. Int. Conf. on Acoustics, Speech and Signal Process. (ICASSP)</em> , May 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://gitlab.com/Tachella/generalized-manipop" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tachella2019rt3d-480.webp 480w,/assets/img/publication_preview/tachella2019rt3d-800.webp 800w,/assets/img/publication_preview/tachella2019rt3d-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tachella2019rt3d.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tachella2019rt3d.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tachella2019rt3d" class="col-sm-8"> <div class="title">Real-time 3D reconstruction from single-photon lidar data using plug-and-play point cloud denoisers</div> <div class="author"> <em>Julian Tachella</em>, Yoann Altmann , Nicolas Mellado , Rachel Tobin , Angus McCarthy , Gerald Buller , Jean-Yves Tourneret , and Steve McLaughlin </div> <div class="periodical"> <em>Nature Communications</em>, May 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.nature.com/articles/s41467-019-12943-7.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://gitlab.com/Tachella/real-time-single-photon-lidar" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Single-photon lidar has emerged as a prime candidate technology for depth imaging through challenging environments. Until now, a major limitation has been the significant amount of time required for the analysis of the recorded data. Here we show a new computational framework for real-time three-dimensional (3D) scene reconstruction from single-photon data. By combining statistical models with highly scalable computational tools from the computer graphics community, we demonstrate 3D reconstruction of complex outdoor scenes with processing times of the order of 20 ms, where the lidar data was acquired in broad daylight from distances up to 320 metres. The proposed method can handle an unknown number of surfaces in each pixel, allowing for target detection and imaging through cluttered scenes. This enables robust, real-time target reconstruction of complex moving scenes, paving the way for single-photon lidar at video rates for practical 3D imaging applications.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <iframe src="https://youtu.be/PzCcAoypUfM" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tachella2019crt3d-480.webp 480w,/assets/img/publication_preview/tachella2019crt3d-800.webp 800w,/assets/img/publication_preview/tachella2019crt3d-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tachella2019crt3d.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tachella2019crt3d.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tachella2019crt3d" class="col-sm-8"> <div class="title">Real-time 3D color imaging with single-photon lidar data</div> <div class="author"> <em>Julian Tachella</em>, Yoann Altmann , Stephen McLaughlin , and Jean-Yves Tourneret </div> <div class="periodical"> <em>In Proc. 8th Int. Workshop Comput. Adv. Multi-Sensor Adap. Process. (CAMSAP)</em> , Dec 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://gitlab.com/Tachella/real-time-single-photon-lidar" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Single-photon lidar devices can acquire 3D data at very long range with high precision. Moreover, recent advances in lidar arrays have enabled acquisitions at very high frame rates. However, these devices place a severe bottleneck on the reconstruction algorithms, which have to handle very large volumes of noisy data. Recently, real-time 3D reconstruction of distributed surfaces has been demonstrated obtaining information at one wavelength. Here, we propose a new algorithm that achieves color 3D reconstruction without increasing the execution time nor the acquisition process of the realtime single-wavelength reconstruction system. The algorithm uses a coded aperture that compresses the data by considering a subset of the wavelengths per pixel. The reconstruction algorithm is based on a plug-and-play denoising framework, which benefits from off-the-shelf point cloud and image de-noisers. Experiments using real lidar data show the competitivity of the proposed method.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Julian Tachella. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>